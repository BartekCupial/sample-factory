{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sf_examples.nethack.models.scaled import CharColorEncoderResnet, ScaledNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bartek/Workspace/ideas/sample-factory/sf_examples/nethack/render_utils/Hack-Regular.ttf\n"
     ]
    }
   ],
   "source": [
    "from sample_factory.cfg.arguments import load_from_checkpoint\n",
    "from sample_factory.utils.attr_dict import AttrDict\n",
    "from sample_factory.algo.utils.env_info import extract_env_info\n",
    "from sample_factory.algo.utils.make_env import make_env_func_batched\n",
    "from sample_factory.model.model_utils import get_rnn_size\n",
    "\n",
    "from sf_examples.nethack.train_nethack import parse_nethack_args, register_nethack_components, make_nethack_actor_critic\n",
    "from sf_examples.nethack.models.utils import scale_width_critic, downscale_first_layer, downscale_last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2024-05-27 14:43:29,852][209200] register_encoder_factory: <function make_nethack_encoder at 0x7b3fd7138ee0>\u001b[0m\n",
      "\u001b[36m[2024-05-27 14:43:29,853][209200] register_actor_critic_factory: <function make_nethack_actor_critic at 0x7b3fd7139090>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env_name = \"challenge\"\n",
    "register_nethack_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = parse_nethack_args(\n",
    "    [\n",
    "        f\"--env={env_name}\",\n",
    "        \"--model=ScaledNet\",\n",
    "        \"--use_resnet=True\",\n",
    "        \"--h_dim=1738\",\n",
    "        \"--rnn_size=1738\",\n",
    "        \"--actor_critic_share_weights=False\",\n",
    "        \"--critic_increase_factor=2\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env_func_batched(cfg, env_config=AttrDict(worker_index=0, vector_index=0, env_id=0))\n",
    "env_info = extract_env_info(env, cfg)\n",
    "\n",
    "obs_space = env_info.obs_space\n",
    "action_space = env.action_space\n",
    "obs, info = env.reset(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2024-05-27 14:43:33,459][209200] RunningMeanStd input shape: (1,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rnn_states = torch.zeros([1, get_rnn_size(cfg)], dtype=torch.float32)\n",
    "model = make_nethack_actor_critic(cfg, obs_space, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_width_critic(model, factor=factor)\n",
    "\n",
    "downscale_first_layer(model.critic_encoder.topline_encoder.msg_fwd, '0', factor)\n",
    "downscale_first_layer(model.critic_encoder.bottomline_encoder.conv_net, '0', factor)\n",
    "downscale_first_layer(model.critic_encoder.screen_encoder.conv_net[0], '0', factor)\n",
    "downscale_first_layer(model.critic_encoder.extract_crop_representation, '0', factor)\n",
    "\n",
    "downscale_last_layer(model.critic, \"critic_linear\", factor)\n",
    "\n",
    "model.critic_encoder.screen_encoder.out_size *= factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': tensor(0.0167, grad_fn=<SqueezeBackward0>),\n",
       " 'action_logits': tensor([[-0.0682,  0.0368, -0.0674,  0.1289,  0.0284,  0.0404,  0.0260, -0.0440,\n",
       "           0.0368, -0.0241,  0.0561, -0.0605,  0.0252, -0.0351,  0.0306,  0.1509,\n",
       "          -0.1443,  0.0058,  0.0551, -0.0392,  0.0716,  0.0833,  0.1486, -0.0617,\n",
       "          -0.0385, -0.0565,  0.1088,  0.0341,  0.0141,  0.1072,  0.0090,  0.0732,\n",
       "          -0.0770,  0.0481,  0.0686,  0.0546,  0.0880, -0.0526,  0.0450, -0.0167,\n",
       "           0.0202, -0.0883, -0.0978, -0.0865, -0.0264, -0.0358, -0.0701, -0.0983,\n",
       "           0.0713,  0.0654, -0.0719,  0.0692,  0.0038, -0.0144,  0.0355, -0.1783,\n",
       "           0.0142,  0.0204, -0.0392,  0.0806,  0.0317,  0.0232, -0.0904,  0.1519,\n",
       "           0.0628, -0.1408, -0.0519,  0.0024, -0.0246, -0.0061,  0.0137,  0.0216,\n",
       "           0.0264,  0.0604,  0.1507, -0.0522, -0.0405,  0.0677,  0.0082,  0.0526,\n",
       "          -0.0601,  0.0098,  0.0258,  0.0578,  0.0570,  0.1510,  0.0259,  0.0474,\n",
       "           0.0135,  0.0109,  0.0328,  0.1746,  0.1348, -0.0722, -0.1466, -0.0892,\n",
       "          -0.1300,  0.0119, -0.1045,  0.0017, -0.0875, -0.0701,  0.0353, -0.0462,\n",
       "          -0.0096, -0.0214, -0.0013,  0.0571, -0.1150,  0.0127, -0.0523,  0.0631,\n",
       "          -0.0307,  0.0887, -0.0530, -0.0035,  0.0245,  0.1159,  0.0988,  0.0361,\n",
       "          -0.1161]], grad_fn=<AddmmBackward0>),\n",
       " 'log_prob_actions': tensor([-4.8257], grad_fn=<ViewBackward0>),\n",
       " 'actions': tensor([105]),\n",
       " 'new_rnn_states': tensor([[ 0.0013,  0.0103, -0.0196,  ...,  0.0091, -0.0147, -0.0109]],\n",
       "        grad_fn=<CatBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(obs, rnn_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = parse_nethack_args(\n",
    "    [\n",
    "        f\"--env={env_name}\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env_func_batched(cfg, env_config=AttrDict(worker_index=0, vector_index=0, env_id=0))\n",
    "env_info = extract_env_info(env, cfg)\n",
    "\n",
    "obs_space = env_info.obs_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScaledNet(cfg, obs_space=obs_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.1639,  ..., 0.1478, 0.2298, 0.1524]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to register hooks\n",
    "handles = []\n",
    "\n",
    "def register_hooks(model):\n",
    "    def hook(module, input, output):\n",
    "        module.output_shape = output.shape\n",
    "        # print(f\"{module.__class__.__name__} output shape: {output.shape}\")\n",
    "\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, (nn.Linear, nn.Conv1d, nn.Conv2d)):\n",
    "            handle = child.register_forward_hook(hook)\n",
    "            handles.append(handle)\n",
    "        else:\n",
    "            register_hooks(child)\n",
    "\n",
    "model = ScaledNet(cfg, obs_space=obs_space)\n",
    "\n",
    "register_hooks(model)\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "model(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScaledNet(\n",
       "  (encoders): ModuleDict()\n",
       "  (crop): Crop()\n",
       "  (extract_crop_representation): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ELU(alpha=1.0)\n",
       "    (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ELU(alpha=1.0)\n",
       "    (12): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ELU(alpha=1.0)\n",
       "  )\n",
       "  (topline_encoder): TopLineEncoder(\n",
       "    (msg_fwd): Sequential(\n",
       "      (0): Linear(in_features=20480, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (bottomline_encoder): BottomLinesEncoder(\n",
       "    (conv_net): Sequential(\n",
       "      (0): Conv1d(2, 32, kernel_size=(8,), stride=(4,))\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "      (2): Conv1d(32, 64, kernel_size=(4,), stride=(1,))\n",
       "      (3): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (fwd_net): Sequential(\n",
       "      (0): Linear(in_features=2304, out_features=128, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ELU(alpha=1.0)\n",
       "    )\n",
       "  )\n",
       "  (screen_encoder): CharColorEncoderResnet(\n",
       "    (conv_net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_head): Sequential(\n",
       "      (0): Linear(in_features=2432, out_features=512, bias=True)\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (char_embeddings): Embedding(256, 16)\n",
       "    (color_embeddings): Embedding(128, 16)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1352, out_features=1738, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1738, out_features=1738, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_width(module, factor=2):\n",
    "    for child in list(module.children()):\n",
    "        \n",
    "        for name, subchild in child.named_children():\n",
    "            if isinstance(subchild, (nn.Conv1d, nn.Conv2d)):\n",
    "                new_in_channels = int(subchild.in_channels * factor)\n",
    "                new_out_channels = int(subchild.out_channels * factor)\n",
    "\n",
    "                new_layer = subchild.__class__(\n",
    "                    new_in_channels, \n",
    "                    new_out_channels, \n",
    "                    kernel_size=subchild.kernel_size, \n",
    "                    bias=subchild.bias is not None, \n",
    "                    stride=subchild.stride, \n",
    "                    padding=subchild.padding, \n",
    "                    dilation=subchild.dilation\n",
    "                )\n",
    "                setattr(child, name, new_layer)\n",
    "                \n",
    "            elif isinstance(subchild, nn.Linear):           \n",
    "                new_in_features = int(subchild.in_features * factor)\n",
    "                new_out_features = int(subchild.out_features * factor)\n",
    "            \n",
    "                new_layer = nn.Linear(new_in_features, new_out_features, bias=subchild.bias is not None)\n",
    "                setattr(child, name, new_layer)\n",
    "            \n",
    "            elif isinstance(subchild, nn.BatchNorm2d):\n",
    "                new_layer = nn.BatchNorm2d(int(subchild.num_features * factor))\n",
    "                setattr(child, name, new_layer)\n",
    "            \n",
    "        scale_width(child, factor=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_first_layer(module, name, factor=2):\n",
    "    cur_layer = module[int(name)]\n",
    "    \n",
    "    if isinstance(cur_layer, (nn.Conv1d, nn.Conv2d)):\n",
    "        new_in_channels = int(cur_layer.in_channels // factor)\n",
    "\n",
    "        new_layer = cur_layer.__class__(\n",
    "            new_in_channels, \n",
    "            cur_layer.out_channels, \n",
    "            kernel_size=cur_layer.kernel_size, \n",
    "            bias=cur_layer.bias is not None, \n",
    "            stride=cur_layer.stride, \n",
    "            padding=cur_layer.padding, \n",
    "            dilation=cur_layer.dilation\n",
    "        )\n",
    "        setattr(module, name, new_layer)\n",
    "        \n",
    "    elif isinstance(cur_layer, nn.Linear):           \n",
    "        new_in_features = int(cur_layer.in_features // factor)\n",
    "    \n",
    "        new_layer = nn.Linear(new_in_features, cur_layer.out_features, bias=cur_layer.bias is not None)\n",
    "        setattr(module, name, new_layer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScaledNet(cfg, obs_space=obs_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_width(model, factor=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_first_layer(model.topline_encoder.msg_fwd, '0', factor)\n",
    "downscale_first_layer(model.bottomline_encoder.conv_net, '0', factor)\n",
    "downscale_first_layer(model.screen_encoder.conv_net[0], '0', factor)\n",
    "downscale_first_layer(model.extract_crop_representation, '0', factor)\n",
    "\n",
    "model.screen_encoder.out_size *= factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6952])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(obs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScaledNet(\n",
       "  (encoders): ModuleDict()\n",
       "  (crop): Crop()\n",
       "  (extract_crop_representation): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ELU(alpha=1.0)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ELU(alpha=1.0)\n",
       "    (12): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ELU(alpha=1.0)\n",
       "  )\n",
       "  (topline_encoder): TopLineEncoder(\n",
       "    (msg_fwd): Sequential(\n",
       "      (0): Linear(in_features=20480, out_features=256, bias=True)\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (bottomline_encoder): BottomLinesEncoder(\n",
       "    (conv_net): Sequential(\n",
       "      (0): Conv1d(2, 128, kernel_size=(8,), stride=(4,))\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "      (2): Conv1d(128, 256, kernel_size=(4,), stride=(1,))\n",
       "      (3): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (fwd_net): Sequential(\n",
       "      (0): Linear(in_features=9216, out_features=512, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ELU(alpha=1.0)\n",
       "    )\n",
       "  )\n",
       "  (screen_encoder): CharColorEncoderResnet(\n",
       "    (conv_net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (2): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ELU(alpha=1.0, inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ELU(alpha=1.0, inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_head): Sequential(\n",
       "      (0): Linear(in_features=9728, out_features=2048, bias=True)\n",
       "      (1): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (char_embeddings): Embedding(256, 16)\n",
       "    (color_embeddings): Embedding(128, 16)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=5408, out_features=6952, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=6952, out_features=6952, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, W = obs[\"tty_chars\"].shape\n",
    "# to process images with CNNs we need channels dim\n",
    "C = 1\n",
    "\n",
    "# Take last channel for now\n",
    "topline = obs[\"tty_chars\"][:, 0].contiguous()\n",
    "bottom_line = obs[\"tty_chars\"][:, -2:].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_first_layer(module, name, factor=2):\n",
    "    cur_layer = module[int(name)]\n",
    "    \n",
    "    if isinstance(cur_layer, (nn.Conv1d, nn.Conv2d)):\n",
    "        new_in_channels = int(cur_layer.in_channels // factor)\n",
    "\n",
    "        new_layer = cur_layer.__class__(\n",
    "            new_in_channels, \n",
    "            cur_layer.out_channels, \n",
    "            kernel_size=cur_layer.kernel_size, \n",
    "            bias=cur_layer.bias is not None, \n",
    "            stride=cur_layer.stride, \n",
    "            padding=cur_layer.padding, \n",
    "            dilation=cur_layer.dilation\n",
    "        )\n",
    "        setattr(module, name, new_layer)\n",
    "        \n",
    "    elif isinstance(cur_layer, nn.Linear):           \n",
    "        new_in_features = int(cur_layer.in_features // factor)\n",
    "    \n",
    "        new_layer = nn.Linear(new_in_features, cur_layer.out_features, bias=cur_layer.bias is not None)\n",
    "        setattr(module, name, new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopLineEncoder(\n",
       "  (msg_fwd): Sequential(\n",
       "    (0): Linear(in_features=40960, out_features=128, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topline_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0'\n",
    "cur_layer = model.topline_encoder.msg_fwd[int(name)]\n",
    "value = nn.Linear(cur_layer.in_features // scale, cur_layer.out_features)\n",
    "setattr(model.topline_encoder.msg_fwd, name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopLineEncoder(\n",
       "  (msg_fwd): Sequential(\n",
       "    (0): Linear(in_features=20480, out_features=128, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topline_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topline_encoder(topline.float(memory_format=torch.contiguous_format).view(B, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottomLinesEncoder(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv1d(4, 64, kernel_size=(8,), stride=(4,))\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Conv1d(64, 128, kernel_size=(4,), stride=(1,))\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (fwd_net): Sequential(\n",
       "    (0): Linear(in_features=4608, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bottomline_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0'\n",
    "cur_layer = model.bottomline_encoder.conv_net[int(name)]\n",
    "value = cur_layer.__class__(\n",
    "    cur_layer.in_channels // scale, \n",
    "    cur_layer.out_channels, \n",
    "    kernel_size=cur_layer.kernel_size, \n",
    "    bias=cur_layer.bias is not None, \n",
    "    stride=cur_layer.stride, \n",
    "    padding=cur_layer.padding, \n",
    "    dilation=cur_layer.dilation\n",
    ")\n",
    "setattr(model.bottomline_encoder.conv_net, name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BottomLinesEncoder(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv1d(2, 64, kernel_size=(8,), stride=(4,))\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Conv1d(64, 128, kernel_size=(4,), stride=(1,))\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (fwd_net): Sequential(\n",
       "    (0): Linear(in_features=4608, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bottomline_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bottomline_encoder(bottom_line.float(memory_format=torch.contiguous_format).view(B, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharColorEncoderResnet(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_head): Sequential(\n",
       "    (0): Linear(in_features=4864, out_features=1024, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (char_embeddings): Embedding(256, 16)\n",
       "  (color_embeddings): Embedding(128, 16)\n",
       ")"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.screen_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0'\n",
    "cur_layer = model.screen_encoder.conv_net[0][int(name)]\n",
    "value = cur_layer.__class__(\n",
    "    cur_layer.in_channels // scale, \n",
    "    cur_layer.out_channels, \n",
    "    kernel_size=cur_layer.kernel_size, \n",
    "    bias=cur_layer.bias is not None, \n",
    "    stride=cur_layer.stride, \n",
    "    padding=cur_layer.padding, \n",
    "    dilation=cur_layer.dilation\n",
    ")\n",
    "setattr(model.screen_encoder.conv_net[0], name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.screen_encoder.out_size *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = '0'\n",
    "# cur_layer = model.screen_encoder.fc_head[int(name)]\n",
    "# value = nn.Linear(cur_layer.in_features // scale, cur_layer.out_features)\n",
    "# setattr(model.screen_encoder.fc_head, name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharColorEncoderResnet(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_head): Sequential(\n",
       "    (0): Linear(in_features=4864, out_features=1024, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (char_embeddings): Embedding(256, 16)\n",
       "  (color_embeddings): Embedding(128, 16)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.screen_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "tty_chars = (\n",
    "    obs[\"tty_chars\"][:, 1:-2]\n",
    "    .contiguous()\n",
    "    .float(memory_format=torch.contiguous_format)\n",
    "    .view(B, C, H - 3, W)\n",
    ")\n",
    "tty_colors = obs[\"tty_colors\"][:, 1:-2].contiguous().view(B, C, H - 3, W)\n",
    "tty_cursor = obs[\"tty_cursor\"].contiguous().view(B, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars, colors = model.screen_encoder._embed(tty_chars, tty_colors)  # 21 x 80\n",
    "x = model.screen_encoder._stack(chars, colors)\n",
    "x = model.screen_encoder.conv_net(x)\n",
    "x = x.view(-1, model.screen_encoder.out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4864])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.screen_encoder(tty_chars, tty_colors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ELU(alpha=1.0)\n",
       "  (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ELU(alpha=1.0)\n",
       "  (12): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ELU(alpha=1.0)\n",
       ")"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extract_crop_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extract_crop_representation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0'\n",
    "cur_layer = model.extract_crop_representation[int(name)]\n",
    "value = cur_layer.__class__(\n",
    "    cur_layer.in_channels // scale, \n",
    "    cur_layer.out_channels, \n",
    "    kernel_size=cur_layer.kernel_size, \n",
    "    bias=cur_layer.bias is not None, \n",
    "    stride=cur_layer.stride, \n",
    "    padding=cur_layer.padding, \n",
    "    dilation=cur_layer.dilation\n",
    ")\n",
    "setattr(model.extract_crop_representation, name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ELU(alpha=1.0)\n",
       "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ELU(alpha=1.0)\n",
       "  (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ELU(alpha=1.0)\n",
       "  (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ELU(alpha=1.0)\n",
       "  (12): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ELU(alpha=1.0)\n",
       ")"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extract_crop_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3476])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(obs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf_nethack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sample_factory.algo.utils.env_info import extract_env_info\n",
    "from sample_factory.algo.utils.make_env import make_env_func_batched\n",
    "from sample_factory.utils.attr_dict import AttrDict\n",
    "from sf_examples.nethack.train_nethack import parse_nethack_args, register_nethack_components\n",
    "from sf_examples.nethack.models.simba import SimBaEncoder\n",
    "from sf_examples.nethack.models.vit import ViTEncoder\n",
    "from sf_examples.nethack.models.chaotic_dwarf import ChaoticDwarvenGPT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2025-01-27 15:36:52,392][76384] register_encoder_factory: <function make_nethack_encoder at 0x70fa55becdc0>\u001b[0m\n",
      "\u001b[36m[2025-01-27 15:36:52,392][76384] register_actor_critic_factory: <function make_nethack_actor_critic at 0x70fa55becca0>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "register_nethack_components()\n",
    "cfg = parse_nethack_args(argv=[\"--env=nethack_score\", \"--add_image_observation=True\"])\n",
    "\n",
    "env = make_env_func_batched(cfg, env_config=AttrDict(worker_index=0, vector_index=0, env_id=0))\n",
    "env_info = extract_env_info(env, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimBa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Dim   64     128    256     512     1024\n",
      "Depth                                          \n",
      "1           1.50M  3.03M  6.21M  13.06M  28.73M\n",
      "2           1.51M  3.04M  6.22M  13.07M  28.75M\n",
      "3           1.54M  3.07M  6.25M  13.11M  28.79M\n",
      "4           1.66M  3.19M  6.37M  13.24M  28.94M\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for hidden_dim in [64, 128, 256, 512, 1024]:\n",
    "    for depth in [1, 2, 3, 4]:\n",
    "        model = SimBaEncoder(\n",
    "            obs_space=env_info.obs_space,\n",
    "            hidden_dim=hidden_dim,\n",
    "            depth=depth,\n",
    "            use_prev_action=cfg.use_prev_action,\n",
    "            use_max_pool=True,\n",
    "            expansion=2,\n",
    "        )\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "        results.append({\n",
    "            \"Hidden Dim\": hidden_dim,\n",
    "            \"Depth\": depth,\n",
    "            \"Model Size\": f\"{total_params / 10**6:.2f}M\"\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "pivot_table = df.pivot(index=\"Depth\", columns=\"Hidden Dim\", values=\"Model Size\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChaoticDwarven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 3.28M\n"
     ]
    }
   ],
   "source": [
    "model = ChaoticDwarvenGPT5(cfg, env_info.obs_space)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model Size: {total_params / 10**6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Dim    64     128    256     512\n",
      "Depth                                  \n",
      "1           1.66M  3.38M  7.07M  15.43M\n",
      "2           1.80M  3.71M  7.86M  17.53M\n",
      "3           1.95M  4.03M  8.64M  19.63M\n",
      "4           2.10M  4.36M  9.43M  21.73M\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for hidden_dim in [64, 128, 256, 512]:\n",
    "    for depth in [1, 2, 3, 4]:\n",
    "        model = ViTEncoder(\n",
    "            obs_space=env_info.obs_space,\n",
    "            hidden_dim=hidden_dim,\n",
    "            depth=depth,\n",
    "            heads=8,\n",
    "            mlp_dim=hidden_dim * 2,\n",
    "            use_prev_action=cfg.use_prev_action,\n",
    "        )\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "        results.append({\n",
    "            \"Hidden Dim\": hidden_dim,\n",
    "            \"Depth\": depth,\n",
    "            \"Model Size\": f\"{total_params / 10**6:.2f}M\"\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "pivot_table = df.pivot(index=\"Depth\", columns=\"Hidden Dim\", values=\"Model Size\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf_nethack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
